# =============================================================================
# EchoJEPA-L Probe: LVEF Regression on EchoNet-Dynamic -- RTX 4090 Single GPU
# =============================================================================
# Usage:
#   python -m evals.main --fname configs/4090/eval/echonet_dynamic_lvef.yaml --devices cuda:0
#
# Before running:
#   1. Download EchoNet-Dynamic from https://echonet.github.io/dynamic/
#   2. Prepare train/val CSVs with Z-score normalized LVEF values:
#        <path_to_video.mp4> <normalized_lvef_value>
#   3. Fit StandardScaler on train split ONLY, then transform all splits
#      EchoNet-Dynamic stats: mean=55.7776, std=12.4064
# =============================================================================

app: vjepa
cpus_per_task: 8
folder: experiments/eval/echonet_dynamic_lvef
mem_per_gpu: 22G
nodes: 1
tasks_per_node: 1              # <--- Single GPU
num_workers: 8

eval_name: video_classification_frozen
resume_checkpoint: true
tag: echojepa-vitl-echonet-dynamic-lvef-4090

experiment:
  classifier:
    task_type: regression
    num_heads: 16
    num_probe_blocks: 4
    num_targets: 1

  data:
    dataset_type: VideoDataset
    dataset_train: data/csv/echonet_dynamic_train.csv    # <--- UPDATE
    dataset_val:   data/csv/echonet_dynamic_val.csv      # <--- UPDATE

    resolution: 112              # RoPE allows flexible resolution; 112 saves memory
    frames_per_clip: 16
    frame_step: 2
    num_segments: 2
    num_views_per_segment: 1

    target_mean: 55.7776         # EchoNet-Dynamic train set mean LVEF
    target_std: 12.4064          # EchoNet-Dynamic train set std LVEF

  optimization:
    batch_size: 2                # Probe is lightweight; 2 fits easily on 4090
    multihead_kwargs:
    # --- Group 1: lr=1e-4 ---
    - final_lr: 0.0
      final_weight_decay: 0.01
      lr: 0.0001
      start_lr: 0.0001
      warmup: 0.0
      weight_decay: 0.01
    - final_lr: 0.0
      final_weight_decay: 0.1
      lr: 0.0001
      start_lr: 0.0001
      warmup: 0.0
      weight_decay: 0.1
    - final_lr: 0.0
      final_weight_decay: 0.4
      lr: 0.0001
      start_lr: 0.0001
      warmup: 0.0
      weight_decay: 0.4

    # --- Group 2: lr=5e-5 ---
    - final_lr: 0.0
      final_weight_decay: 0.01
      lr: 0.00005
      start_lr: 0.00005
      warmup: 0.0
      weight_decay: 0.01
    - final_lr: 0.0
      final_weight_decay: 0.1
      lr: 0.00005
      start_lr: 0.00005
      warmup: 0.0
      weight_decay: 0.1
    - final_lr: 0.0
      final_weight_decay: 0.4
      lr: 0.00005
      start_lr: 0.00005
      warmup: 0.0
      weight_decay: 0.4

    num_epochs: 20
    use_bfloat16: true
    use_pos_embed: false

model_kwargs:
  checkpoint: checkpoints/vitl.pt        # <--- V-JEPA2 ViT-L (or your domain-pretrained checkpoint)
  module_name: evals.video_classification_frozen.modelcustom.vit_encoder_multiclip
  pretrain_kwargs:
    encoder:
      checkpoint_key: target_encoder
      img_temporal_dim_size: null
      model_name: vit_large
      patch_size: 16
      tubelet_size: 2
      uniform_power: true
      use_rope: true
  wrapper_kwargs:
    max_frames: 128
    use_pos_embed: false
