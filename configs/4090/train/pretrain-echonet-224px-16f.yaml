# =============================================================================
# EchoJEPA ViT-L Pretraining on Combined Cardiac Echo -- RTX 4090 (24GB)
# =============================================================================
# Dataset: EchoNet-Dynamic + Pediatric A4C + PSAX (17,840 videos)
# Initializes from V-JEPA2 ViT-L pretrained weights.
#
# Usage:
#   python -m app.main --fname configs/4090/train/pretrain-echonet-224px-16f.yaml --devices cuda:0

app: vjepa
nodes: 1
tasks_per_node: 1
cpus_per_task: 8
mem_per_gpu: 22G

folder: experiments/pretrain/echonet_combined_vitl_224px_16f

data:
  dataset_type: VideoDataset
  datasets:
  - data/csv/pretrain_combined.csv
  datasets_weights:
  - 1.0
  batch_size: 16
  crop_size: 224
  patch_size: 16
  dataset_fpcs:
  - 16
  fps: 8
  tubelet_size: 2
  num_workers: 8
  persistent_workers: true
  pin_mem: true

data_aug:
  auto_augment: false
  motion_shift: false
  random_resize_aspect_ratio: [0.9, 1.1]
  random_resize_scale: [0.5, 1.0]
  reprob: 0.0

loss:
  loss_exp: 1.0

mask:
- aspect_ratio: [0.75, 1.5]
  full_complement: false
  max_keep: null
  max_temporal_keep: 1.0
  num_blocks: 8
  spatial_scale: [0.15, 0.15]
  temporal_scale: [1.0, 1.0]
- aspect_ratio: [0.75, 1.5]
  full_complement: false
  max_keep: null
  max_temporal_keep: 1.0
  num_blocks: 2
  spatial_scale: [0.7, 0.7]
  temporal_scale: [1.0, 1.0]

meta:
  dtype: bfloat16
  eval_freq: 100
  load_checkpoint: false
  read_checkpoint: null
  save_every_freq: 5
  seed: 234
  use_sdpa: true

model:
  model_name: vit_large
  pred_depth: 12
  pred_embed_dim: 384
  pred_num_heads: 12
  uniform_power: true
  use_activation_checkpointing: true
  use_mask_tokens: true
  num_mask_tokens: 10
  use_rope: true
  zero_init_mask_tokens: true

optimization:
  is_anneal: false
  force_load_pretrain: true
  anneal_ckpt: checkpoints/vitl.pt

  ema: [0.99925, 0.99925]
  weight_decay: 0.04
  final_weight_decay: 0.04

  ipe: 300
  ipe_scale: 1.25

  start_lr: 3.0e-6
  lr: 3.0e-5
  final_lr: 3.0e-5

  warmup: 40
  epochs: 100                  # Reduced from 240 (smaller dataset than MIMIC)
